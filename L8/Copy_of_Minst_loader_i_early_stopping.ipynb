{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bHf2S-VjaREW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A5X_m_NBaTZ5"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jnoMorHvaYQw"
   },
   "outputs": [],
   "source": [
    "class NeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.layer2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.layer2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v9fB7PXmadUS"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, n_epochs=100, patience=5):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.reshape(-1, 28 * 28)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(images)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                images = images.reshape(-1, 28 * 28)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        accuracy = 100. * correct / len(val_loader.dataset)\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{n_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Plotting losses and accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\", color=\"orange\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bymqbWaBag5b",
    "outputId": "90376d6f-6542-4134-ada2-029ef27c5649"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "n_epochs = 20\n",
    "patience = 5\n",
    "\n",
    "# Data transformation and loading\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7BIb5HZUajYB"
   },
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_layer_size = 100\n",
    "output_size = 10\n",
    "model = NeuralNetModel(input_size, hidden_layer_size, output_size).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PkEa9uC6aliw",
    "outputId": "510e23a3-e0b5-4b6d-dd3a-77cf0d7e9bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.4300 - Val Loss: 0.2754 - Val Accuracy: 91.99%\n",
      "Validation loss decreased (inf --> 0.275433). Saving model...\n",
      "Epoch 2/20 - Train Loss: 0.2435 - Val Loss: 0.2104 - Val Accuracy: 94.17%\n",
      "Validation loss decreased (0.275433 --> 0.210435). Saving model...\n",
      "Epoch 3/20 - Train Loss: 0.1853 - Val Loss: 0.1714 - Val Accuracy: 95.12%\n",
      "Validation loss decreased (0.210435 --> 0.171395). Saving model...\n",
      "Epoch 4/20 - Train Loss: 0.1523 - Val Loss: 0.1638 - Val Accuracy: 95.30%\n",
      "Validation loss decreased (0.171395 --> 0.163802). Saving model...\n",
      "Epoch 5/20 - Train Loss: 0.1297 - Val Loss: 0.1490 - Val Accuracy: 95.38%\n",
      "Validation loss decreased (0.163802 --> 0.148977). Saving model...\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "train(model, train_loader, val_loader, loss_function, optimizer, n_epochs=n_epochs, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
